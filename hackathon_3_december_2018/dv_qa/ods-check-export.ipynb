{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# https://stackoverflow.com/questions/36587211/easiest-way-to-read-csv-files-with-multiprocessing-in-pandas\n",
    "# http://python-3.ru/page/multiprocessing\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаю/обнуляю список файлов \n",
    "files_full_path_list = list()\n",
    "\n",
    "# Путь к корневому каталогу файлов\n",
    "files_path = '/opt/app/data/shared/latest_dump/*/*.json'\n",
    "# files_path = '/opt/app/data/shared/latest_dump/*/2018*.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаю перечень полных пути файлов в подкаталогах\n",
    "for file_name in glob.glob(files_path, recursive=True):\n",
    "    # Добавляю полный путь в список\n",
    "    files_full_path_list.append(file_name)\n",
    "    \n",
    "files_full_path_list.sort()\n",
    "\n",
    "print (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'Количество файлов:', len(files_full_path_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_full_path_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.path.getsize('/opt/app/data/shared/latest_dump/___top_links/2018-08-06.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -all /opt/app/data/shared/latest_dump/___top_links/2018-08-06.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # CPU times: user 6min 38s, sys: 36.4 s, total: 7min 15s\n",
    "\n",
    "# files_df = pd.DataFrame()\n",
    "\n",
    "# for file in files_full_path_list:\n",
    "\n",
    "#     file_size = os.path.getsize(file)\n",
    "    \n",
    "#     # re.findall('dump/(.+?)/\\d', '/opt/app/data/shared/latest_dump/___top_links/2018-08-06.json')[0]\n",
    "#     file_cat = re.findall('dump/(.+?)/\\d', file)[0]\n",
    "    \n",
    "#     # re.findall('(\\d\\d\\d\\d-\\d\\d-\\d\\d)', '/opt/app/data/shared/latest_dump/___top_links/2018-08-06.json')[0]\n",
    "#     file_date = re.findall('(\\d\\d\\d\\d-\\d\\d-\\d\\d)', file)[0]\n",
    "    \n",
    "#     list = [[file, file_size, file_cat, file_date]]\n",
    "    \n",
    "#     files_df = files_df.append(pd.DataFrame(list, columns=['file', 'file_size', 'file_cat', 'file_date']),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df = pd.DataFrame()\n",
    "\n",
    "def get_file_info(file):\n",
    "    file_size = os.path.getsize(file)\n",
    "\n",
    "    # re.findall('dump/(.+?)/\\d', '/opt/app/data/shared/latest_dump/___top_links/2018-08-06.json')[0]\n",
    "    file_cat = re.findall('dump/(.+?)/\\d', file)[0]\n",
    "\n",
    "    # re.findall('(\\d\\d\\d\\d-\\d\\d-\\d\\d)', '/opt/app/data/shared/latest_dump/___top_links/2018-08-06.json')[0]\n",
    "    file_date = re.findall('(\\d\\d\\d\\d-\\d\\d-\\d\\d)', file)[0]\n",
    "\n",
    "    list = [[file, file_size, file_cat, file_date]]\n",
    "    \n",
    "    return pd.DataFrame(list, columns=['file', 'file_size', 'file_cat', 'file_date'])\n",
    "\n",
    "pool = Pool(processes=10)\n",
    "df_list = pool.map(get_file_info, files_full_path_list)\n",
    "\n",
    "files_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df['file_date'] = pd.to_datetime(files_df['file_date'], format='%Y-%m-%d')\n",
    "files_df['file_size'] = files_df['file_size'].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df[['file_cat']]\\\n",
    "        .groupby(['file_cat'])['file_cat'] \\\n",
    "        .count() \\\n",
    "        .reset_index(name='count') \\\n",
    "        .sort_values(['count'], ascending=False) \\\n",
    "        .head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df[['file_cat', 'file_size']]\\\n",
    "        .groupby(['file_cat'])['file_size'] \\\n",
    "        .sum() \\\n",
    "        .reset_index(name='sum_kilobytes') \\\n",
    "        .sort_values(['sum_kilobytes'], ascending=False) \\\n",
    "        .head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "from multiprocessing import Pool\n",
    "\n",
    "# wrap your csv importer in a function that can be mapped\n",
    "def read_csv(filename):\n",
    "    'converts a filename to a pandas dataframe'\n",
    "    return pd.read_csv(filename)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # set up your pool\n",
    "    pool = Pool(processes=8) # or whatever your hardware can support\n",
    "\n",
    "    # get a list of file names\n",
    "    files = os.listdir('.')\n",
    "    file_list = [filename for filename in files if filename.split('.')[1]=='csv']\n",
    "\n",
    "    # have your pool map the file names to dataframes\n",
    "    df_list = pool.map(read_csv, file_list)\n",
    "\n",
    "    # reduce the list of dataframes to a single dataframe\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def doubler(number):\n",
    "    return number * 2\n",
    " \n",
    "numbers = [5, 10, 20]\n",
    "pool = Pool(processes=3)\n",
    "print(pool.map(doubler, numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сколько файлов по каталогам и какого размера каталоги?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сколько служебных сообщений?\n",
    "user leave channel \n",
    "user enter channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаю пустой dataframe для данных их файлов\n",
    "json_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Наполняю данными о сообщениях за 2018 год dataframe (1min 31s) без multiprocessing\n",
    "# Переделать на multiprocessing\n",
    "\n",
    "for file in files_full_path_list:\n",
    "    # Читаю файлы в dataframe\n",
    "    data_parsed = json.loads(open(file).read())\n",
    "    df = json_normalize(data_parsed)\n",
    "    # Добавляю имя файла в dataframe для дальнейшего получения даты и названия канал\n",
    "    df.insert(loc=0, column='FILE', value=file)\n",
    "#     print (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'Добавляю содержимое файла в dataframe', file, round(os.path.getsize(file_name)/1000/1000,2), 'мегабайт')\n",
    "    json_df = json_df.append(df, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Сохраняю dataframe в csv\n",
    "\n",
    "# csv_file_name = '2018_ods_raw_new.csv'\n",
    "# csv_file_dir = '/opt/app/data/'\n",
    "# csv_file_path = csv_file_dir + csv_file_name\n",
    "\n",
    "# # Проверка существует ли файл. Если существует удаляю\n",
    "# if os.path.exists(csv_file_path):\n",
    "#     os.remove(csv_file_name)\n",
    "   \n",
    "# print (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'Добавляю содержимое dataframe в csv', csv_file_path) \n",
    "# json_df.to_csv(csv_file_name, sep='|', index=False, encoding='utf-8')\n",
    "\n",
    "# print (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), \\\n",
    "#        'Размер csv файла:', \\\n",
    "#        round(os.path.getsize(csv_file_path)/1000/1000,3), \\\n",
    "#        'Мегабайт')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
